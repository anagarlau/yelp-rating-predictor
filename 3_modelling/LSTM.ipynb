{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# LSTM Rating Classifier using Word Embeddings"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Q:\n",
    "https://www.youtube.com/watch?v=nam2zR7p7Os\n",
    "https://www.youtube.com/watch?v=Wp-Wb456kSU\n",
    "https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from keras.preprocessing.text import one_hot\n",
    "from keras.utils import pad_sequences # not preprocessing.sequence (deprecated)\n",
    "from numpy import asarray , array\n",
    "from numpy import zeros\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten, Embedding, LSTM\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [],
   "source": [
    "yelp = pd.read_csv(\"../2_text_preprocessing/cleaned_data_yelp.csv\",index_col=None)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Word Embeddings with Keras"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [
    {
     "data": {
      "text/plain": "{'der': 1,\n 'sein': 2,\n 'und': 3,\n 'ein': 4,\n 'in': 5,\n 'ich': 6,\n 'zu': 7,\n 'haben': 8,\n 'es': 9,\n 'nicht': 10,\n 'sehr': 11,\n 'auch': 12,\n 'gut': 13,\n 'mit': 14,\n 'wir': 15,\n 'man': 16,\n 'aber': 17,\n 'werden': 18,\n 'essen': 19,\n 'für': 20,\n 'auf': 21,\n 'an': 22,\n 'sich': 23,\n 'können': 24,\n 'von': 25,\n 'lecker': 26,\n 'so': 27,\n 'hier': 28,\n 'noch': 29,\n 'als': 30,\n 'geben': 31,\n 'bei': 32,\n 'mein': 33,\n 'alle': 34,\n 'restaurant': 35,\n 'nur': 36,\n 'preis': 37,\n 'mal': 38,\n 'kommen': 39,\n 'dieser': 40,\n 'da': 41,\n 'etwas': 42,\n 'service': 43,\n 'dass': 44,\n 'wie': 45,\n 'wieder': 46,\n 'freundlich': 47,\n 'nach': 48,\n 'wenn': 49,\n 'immer': 50,\n 'dann': 51,\n 'schon': 52,\n 'klein': 53,\n 'nett': 54,\n 'aus': 55,\n 'kein': 56,\n 'oder': 57,\n 'wirklich': 58,\n 'bedienung': 59,\n 'super': 60,\n 'was': 61,\n 'ganz': 62,\n 'laden': 63,\n 'uns': 64,\n 'leider': 65,\n 'berlin': 66,\n 'mehr': 67,\n 'tisch': 68,\n 'gehen': 69,\n 'schön': 70,\n 'einfach': 71,\n 'finden': 72,\n 'groß': 73,\n 'jeder': 74,\n 'mir': 75,\n 'schmecken': 76,\n 'anderer': 77,\n 'machen': 78,\n 'um': 79,\n 'dort': 80,\n 'wer': 81,\n 'toll': 82,\n 'frisch': 83,\n 'sie': 84,\n 'küche': 85,\n 'vor': 86,\n 'unser': 87,\n 'ambiente': 88,\n 'gericht': 89,\n 'sollen': 90,\n 'viel': 91,\n 'empfehlen': 92,\n 'bekommen': 93,\n 'schnell': 94,\n 'mich': 95,\n 'bestellen': 96,\n 'abend': 97,\n 'ja': 98,\n 'dazu': 99,\n 'personal': 100,\n 'voll': 101,\n 'also': 102,\n 'wollen': 103,\n 'muss': 104,\n 'gerne': 105,\n 'doch': 106,\n 'aller': 107,\n 'qualität': 108,\n 'sagen': 109,\n 'bis': 110,\n 'stern': 111,\n 'eher': 112,\n 'gemütlich': 113,\n 'besuch': 114,\n 'vieler': 115,\n 'fleisch': 116,\n 'absolut': 117,\n 'über': 118,\n 'ohne': 119,\n 'karte': 120,\n 'sitzen': 121,\n 'richtig': 122,\n 'nichts': 123,\n 'zwei': 124,\n 'lokal': 125,\n 'sehen': 126,\n 'durch': 127,\n 'portion': 128,\n 'atmosphäre': 129,\n 'allerdings': 130,\n 'kellner': 131,\n 'echt': 132,\n 'schnitzel': 133,\n 'er': 134,\n 'euro': 135,\n 'salat': 136,\n 'ihr': 137,\n 'wohl': 138,\n 'stehen': 139,\n 'recht': 140,\n 'fall': 141,\n 'einer': 142,\n 'wenig': 143,\n 'erster': 144,\n 'aufmerksam': 145,\n 'pizza': 146,\n 'selbst': 147,\n 'platz': 148,\n 'ok': 149,\n 'liegen': 150,\n 'burger': 151,\n 'wein': 152,\n 'denn': 153,\n 'warten': 154,\n 'dafür': 155,\n 'fast': 156,\n 'hoch': 157,\n 'auswahl': 158,\n 'reservieren': 159,\n 'geschmack': 160,\n 'speisen': 161,\n 'angenehm': 162,\n 'eur': 163,\n 'weil': 164,\n 'lassen': 165,\n 'bier': 166,\n 'ob': 167,\n 'eigentlich': 168,\n 'zeit': 169,\n 'einmal': 170,\n 'hin': 171,\n 'jedoch': 172,\n 'besonders': 173,\n 'teller': 174,\n 'servieren': 175,\n 'nehmen': 176,\n 'berliner': 177,\n 'lang': 178,\n 'jetzt': 179,\n 'probieren': 180,\n 'vielleicht': 181,\n 'zwar': 182,\n 'jahr': 183,\n 'freund': 184,\n 'person': 185,\n 'mussen': 186,\n 'natürlich': 187,\n 'gäste': 188,\n 'nun': 189,\n 'gleich': 190,\n 'schlecht': 191,\n 'top': 192,\n 'günstig': 193,\n 'besuchen': 194,\n 'letzter': 195,\n 'nie': 196,\n 'zubereitet': 197,\n 'neu': 198,\n 'brot': 199,\n 'gerade': 200,\n 'laut': 201,\n 'perfekt': 202,\n 'empfehlung': 203,\n 'weit': 204,\n 'einrichtung': 205,\n 'möchten': 206,\n 'trotzdem': 207,\n 'direkt': 208,\n 'sondern': 209,\n 'getränk': 210,\n 'ab': 211,\n 'teuer': 212,\n 'beide': 213,\n 'minute': 214,\n 'mitte': 215,\n 'tag': 216,\n 'suppe': 217,\n 'fazit': 218,\n 'mögen': 219,\n 'kurz': 220,\n 'unbedingt': 221,\n 'unter': 222,\n 'steak': 223,\n 'heute': 224,\n 'paar': 225,\n 'lange': 226,\n 'nächster': 227,\n 'draußen': 228,\n 'insgesamt': 229,\n 'gar': 230,\n 'bleiben': 231,\n 'welcher': 232,\n 'deutsch': 233,\n 'geschmacklich': 234,\n 'erst': 235,\n 'ordnung': 236,\n 'bieten': 237,\n 'fühlen': 238,\n 'vegetarisch': 239,\n 'einiger': 240,\n 'weiter': 241,\n 'authentisch': 242,\n 'sicher': 243,\n 'einzig': 244,\n 'ziemlich': 245,\n 'lage': 246,\n 'uhr': 247,\n 'reservierung': 248,\n 'leute': 249,\n 'vorspeise': 250,\n 'erwarten': 251,\n 'satt': 252,\n 'oft': 253,\n 'verschieden': 254,\n 'weniger': 255,\n 'leistung': 256,\n 'wissen': 257,\n 'genau': 258,\n 'wert': 259,\n 'scharf': 260,\n 'gemüse': 261,\n 'alt': 262,\n 'sonst': 263,\n 'daher': 264,\n 'dabei': 265,\n 'bestellung': 266,\n 'hervorragend': 267,\n 'obwohl': 268,\n 'speisekarte': 269,\n 'zuvorkommend': 270,\n 'kennen': 271,\n 'sogar': 272,\n 'fallen': 273,\n 'speise': 274,\n 'wo': 275,\n 'gegessen': 276,\n 'drei': 277,\n 'dürfen': 278,\n 'bisschen': 279,\n 'leckere': 280,\n 'klasse': 281,\n 'haus': 282,\n 'seit': 283,\n 'zufrieden': 284,\n 'bringen': 285,\n 'punkt': 286,\n 'tun': 287,\n 'denken': 288,\n 'angemessen': 289,\n 'müssen': 290,\n 'trinken': 291,\n 'besonderer': 292,\n 'wartezeit': 293,\n 'tapa': 294,\n 'sauce': 295,\n 'sowie': 296,\n 'warm': 297,\n 'fragen': 298,\n 'pommes': 299,\n 'ebenfalls': 300,\n 'gast': 301,\n 'fein': 302,\n 'beilage': 303,\n 'offen': 304,\n 'sommer': 305,\n 'kalt': 306,\n 'zutat': 307,\n 'frühstück': 308,\n 'location': 309,\n 'positiv': 310,\n 'bewertung': 311,\n 'ca': 312,\n 'zwischen': 313,\n 'grill': 314,\n 'typisch': 315,\n 'enttäuschen': 316,\n 'empfehlenswert': 317,\n 'definitiv': 318,\n 'eben': 319,\n 'leicht': 320,\n 'burrito': 321,\n 'lohnen': 322,\n 'stimmen': 323,\n 'spät': 324,\n 'wunderbar': 325,\n 'trotz': 326,\n 'abends': 327,\n 'kaffee': 328,\n 'stunde': 329,\n 'woche': 330,\n 'wirken': 331,\n 'her': 332,\n 'total': 333,\n 'klar': 334,\n 'kaum': 335,\n 'bedienen': 336,\n 'kosten': 337,\n 'wegen': 338,\n 'vorspeisen': 339,\n 'damit': 340,\n 'gern': 341,\n 'neben': 342,\n 'dessert': 343,\n 'vorher': 344,\n 'schmackhaft': 345,\n 'passen': 346,\n 'hingehen': 347,\n 'blick': 348,\n 'schade': 349,\n 'einrichten': 350,\n 'eindruck': 351,\n 'tische': 352,\n 'durchaus': 353,\n 'halten': 354,\n 'preislich': 355,\n 'irgendwie': 356,\n 'bisher': 357,\n 'bar': 358,\n 'frei': 359,\n 'fair': 360,\n 'anbieten': 361,\n 'davon': 362,\n 'weg': 363,\n 'art': 364,\n 'überzeugen': 365,\n 'persönlich': 366,\n 'dennoch': 367,\n 'relativ': 368,\n 'anders': 369,\n 'menü': 370,\n 'gehören': 371,\n 'bezahlen': 372,\n 'daß': 373,\n 'scheinen': 374,\n 'ente': 375,\n 'sauber': 376,\n 'entscheiden': 377,\n 'glück': 378,\n 'halb': 379,\n 'leistungsverhältnis': 380,\n 'bereits': 381,\n 'fehlen': 382,\n 'köstlich': 383,\n 'suchen': 384,\n 'extrem': 385,\n 'normal': 386,\n 'danach': 387,\n 'begeistert': 388,\n 'pasta': 389,\n 'verhältnis': 390,\n 'rechnung': 391,\n 'hauptgericht': 392,\n 'stück': 393,\n 'wählen': 394,\n 'okay': 395,\n 'ecke': 396,\n 'italienisch': 397,\n 'nochmal': 398,\n 'getränke': 399,\n 'gruppe': 400,\n 'sofort': 401,\n 'reis': 402,\n 'genießen': 403,\n 'völlig': 404,\n 'endlich': 405,\n 'fisch': 406,\n 'angebot': 407,\n 'ende': 408,\n 'selten': 409,\n 'stadt': 410,\n 'zweiter': 411,\n 'ansonsten': 412,\n 'meinen': 413,\n 'nähe': 414,\n 'ordentlich': 415,\n 'reichen': 416,\n 'bzw': 417,\n 'nachdem': 418,\n 'manchmal': 419,\n 'soße': 420,\n 'stellen': 421,\n 'aufgrund': 422,\n 'darauf': 423,\n 'gestern': 424,\n 'ort': 425,\n 'jung': 426,\n 'würzen': 427,\n 'selber': 428,\n 'ausprobieren': 429,\n 'eng': 430,\n 'leer': 431,\n 'anrichten': 432,\n 'freundin': 433,\n 'interessant': 434,\n 'platte': 435,\n 'name': 436,\n 'vorbei': 437,\n 'unglaublich': 438,\n 'hunger': 439,\n 'zart': 440,\n 'geld': 441,\n 'halt': 442,\n 'früh': 443,\n 'toilette': 444,\n 'habn': 445,\n 'imbiss': 446,\n 'gegend': 447,\n 'extra': 448,\n 'asiatisch': 449,\n 'freuen': 450,\n 'lieben': 451,\n 'zusammen': 452,\n 'musik': 453,\n 'überhaupt': 454,\n 'wasser': 455,\n 'sowohl': 456,\n 'sushi': 457,\n 'schaffen': 458,\n 'glas': 459,\n 'mann': 460,\n 'teilweise': 461,\n 'kellnerin': 462,\n 'verstehen': 463,\n 'je': 464,\n 'vergessen': 465,\n 'nachtisch': 466,\n 'wiener': 467,\n 'vegan': 468,\n 'trocken': 469,\n 'dauern': 470,\n 'italiener': 471,\n 'modern': 472,\n 'bitte': 473,\n 'wünschen': 474,\n 'thai': 475,\n 'herzlich': 476,\n 'süß': 477,\n 'falafel': 478,\n 'kartoffel': 479,\n 'gessen': 480,\n 'begleitung': 481,\n 'mittags': 482,\n 'riesig': 483,\n 'wedding': 484,\n 'koch': 485,\n 'warum': 486,\n 'problem': 487,\n 'laufen': 488,\n 'koreanisch': 489,\n 'knusprig': 490,\n 'kochen': 491,\n 'reichlich': 492,\n 'hausgemacht': 493,\n 'ruhig': 494,\n 'menge': 495,\n 'gemischt': 496,\n 'hauptgang': 497,\n 'sprechen': 498,\n 'sache': 499,\n 'cool': 500,\n 'drinnen': 501,\n 'gefühl': 502,\n 'außerdem': 503,\n 'zahlen': 504,\n 'vier': 505,\n 'unfreundlich': 506,\n 'bestellt': 507,\n 'egal': 508,\n 'falsch': 509,\n 'deutlich': 510,\n 'locker': 511,\n 'hauptspeise': 512,\n 'kölsch': 513,\n 'erleben': 514,\n 'flasche': 515,\n 'deshalb': 516,\n 'konzept': 517,\n 'lieber': 518,\n 'publikum': 519,\n 'gästen': 520,\n 'erinnern': 521,\n 'frau': 522,\n 'dank': 523,\n 'tourist': 524,\n 'käse': 525,\n 'setzen': 526,\n 'rot': 527,\n 'fünf': 528,\n 'chef': 529,\n 'schwer': 530,\n 'teilen': 531,\n 'treffen': 532,\n 'während': 533,\n 'du': 534,\n 'raum': 535,\n 'ausreichend': 536,\n 'wiederkommen': 537,\n 'genug': 538,\n 'entspannt': 539,\n 'möglich': 540,\n 'zumindest': 541,\n 'euch': 542,\n 'curry': 543,\n 'gegen': 544,\n 'gebraten': 545,\n 'ne': 546,\n 'mehrere': 547,\n 'sicherlich': 548,\n 'innen': 549,\n 'rein': 550,\n 'hammer': 551,\n 'meinung': 552,\n 'ebenso': 553,\n 'teil': 554,\n 'terrasse': 555,\n 'meist': 556,\n 'großartig': 557,\n 'straße': 558,\n 'idee': 559,\n 'gibts': 560,\n 'lust': 561,\n 'übrigens': 562,\n 'caf': 563,\n 'selbstgemacht': 564,\n 'mensch': 565,\n 'gehoben': 566,\n 'schaden': 567,\n 'bestehen': 568,\n 'wahl': 569,\n 'team': 570,\n 'griechisch': 571,\n 'billig': 572,\n 'min': 573,\n 'sandwich': 574,\n 'frage': 575,\n 'grund': 576,\n 'leben': 577,\n 'hinter': 578,\n 'tresen': 579,\n 'überraschen': 580,\n 'tipp': 581,\n 'jedenfalls': 582,\n 'ramen': 583,\n 'brauchen': 584,\n 'mitnehmen': 585,\n 'zweit': 586,\n 'am': 587,\n 'schreiben': 588,\n 'außen': 589,\n 'bekannt': 590,\n 'spree': 591,\n 'tee': 592,\n 'befinden': 593,\n 'komplett': 594,\n 'größe': 595,\n 'pro': 596,\n 'solcher': 597,\n 'mitarbeiter': 598,\n 'drauf': 599,\n 'preiswert': 600,\n 'biergarten': 601,\n 'flammkuch': 602,\n 'plätz': 603,\n 'liebe': 604,\n 'kulinarisch': 605,\n 'empfehlenswern': 606,\n 'auge': 607,\n 'fantastisch': 608,\n 'wochenende': 609,\n 'schauen': 610,\n 'glauben': 611,\n 'eigen': 612,\n 'dolores': 613,\n 'grün': 614,\n 'ehrlich': 615,\n 'arbeiten': 616,\n 'führen': 617,\n 'wichtig': 618,\n 'wobei': 619,\n 'merken': 620,\n 'lesen': 621,\n 'tatsächlich': 622,\n 'zudem': 623,\n 'kart': 624,\n 'mittlerweile': 625,\n 'passend': 626,\n 'nudel': 627,\n 'stören': 628,\n 'begeistern': 629,\n 'kollege': 630,\n 'weder': 631,\n 'schlicht': 632,\n 'mittag': 633,\n 'ziehen': 634,\n 'theke': 635,\n 'üblich': 636,\n 'heiß': 637,\n 'nix': 638,\n 'genuss': 639,\n 'kuchen': 640,\n 'royal': 641,\n 'rund': 642,\n 'knapp': 643,\n 'flott': 644,\n 'stimmung': 645,\n 'statt': 646,\n 'rustikal': 647,\n 'tür': 648,\n 'ihn': 649,\n 'abzug': 650,\n 'wohnen': 651,\n 'vegetarier': 652,\n 'urig': 653,\n 'hotel': 654,\n 'bestimmen': 655,\n 'liebevoll': 656,\n 'professionell': 657,\n 'erklären': 658,\n 'versuchen': 659,\n 'nachfrage': 660,\n 'food': 661,\n 'erlebnis': 662,\n 'kartoffelsalat': 663,\n 'japanisch': 664,\n 'medium': 665,\n 'kneipe': 666,\n 'daran': 667,\n 'stark': 668,\n 'durchschnittlich': 669,\n 'kind': 670,\n 'regelmäßig': 671,\n 'highlight': 672,\n 'spezialität': 673,\n 'los': 674,\n 'peking': 675,\n 'mittagstisch': 676,\n 'diverser': 677,\n 'kunde': 678,\n 'verdienen': 679,\n 'erhalten': 680,\n 'bald': 681,\n 'etc': 682,\n 'wahrscheinlich': 683,\n 'übersichtlich': 684,\n 'stets': 685,\n 'yam': 686,\n 'gegenüber': 687,\n 'entdecken': 688,\n 'jemand': 689,\n 'charme': 690,\n 'verbringen': 691,\n 'tapas': 692,\n 'mittagessen': 693,\n 'tofu': 694,\n 'klassisch': 695,\n 'dünn': 696,\n 'pizze': 697,\n 'arabisch': 698,\n 'wetter': 699,\n 'rest': 700,\n 'oben': 701,\n 'spaß': 702,\n 'traum': 703,\n 'übrig': 704,\n 'glücklich': 705,\n 'chinesisch': 706,\n 'meister': 707,\n 'etwa': 708,\n 'gefüllt': 709,\n 'sonntag': 710,\n 'negativ': 711,\n 'allgemein': 712,\n 'bild': 713,\n 'füllen': 714,\n 'mancher': 715,\n 'vorhanden': 716,\n 'heißen': 717,\n 'überteuert': 718,\n 'ähnlich': 719,\n 'ansprechend': 720,\n 'gelungen': 721,\n 'saftig': 722,\n 'schnitzelei': 723,\n 'ständig': 724,\n 'gang': 725,\n 'brunch': 726,\n 'lustig': 727,\n 'geheimtipp': 728,\n 'familie': 729,\n 'allein': 730,\n 'lieb': 731,\n 'fertig': 732,\n 'vietnamesisch': 733,\n 'qype': 734,\n 'dick': 735,\n 'niveau': 736,\n 'auszeichnen': 737,\n 'somit': 738,\n 'begrüßen': 739,\n 'belegen': 740,\n 'original': 741,\n 'freundlichkeit': 742,\n 'danken': 743,\n 'durchschnitt': 744,\n 'jeweils': 745,\n 'erfahrung': 746,\n 'landen': 747,\n 'lunch': 748,\n 'seite': 749,\n 'bahnhof': 750,\n 'einige': 751,\n 'insbesondere': 752,\n 'beilag': 753,\n 'sorte': 754,\n 'alternative': 755,\n 'zubereitung': 756,\n 'naja': 757,\n 'sodass': 758,\n 'entsprechend': 759,\n 'mittagszeit': 760,\n 'legen': 761,\n 'hübsch': 762,\n 'friedrichstraße': 763,\n 'erstmal': 764,\n 'erwartung': 765,\n 'heben': 766,\n 'öfter': 767,\n 'vollkommen': 768,\n 'nein': 769,\n 'lachs': 770,\n 'rind': 771,\n 'spätzle': 772,\n 'drin': 773,\n 'mitten': 774,\n 'vergleich': 775,\n 'kreativ': 776,\n 'hause': 777,\n 'sympathisch': 778,\n 'hochwertig': 779,\n 'bohne': 780,\n 'mittagspause': 781,\n 'empfinden': 782,\n 'höflich': 783,\n 'zügig': 784,\n 'espresso': 785,\n 'vorweg': 786,\n 'gelingen': 787,\n 'fest': 788,\n 'wort': 789,\n 'hand': 790,\n 'genial': 791,\n 'französisch': 792,\n 'dudu': 793,\n 'schwarz': 794,\n 'kompetent': 795,\n 'testen': 796,\n 'de': 797,\n 'dunkel': 798,\n 'zusätzlich': 799,\n 'zeigen': 800,\n 'berg': 801,\n 'qualitativ': 802,\n 'langsam': 803,\n 'bestimmt': 804,\n 'wunderschön': 805,\n 'gegrillt': 806,\n 'bbq': 807,\n 'mega': 808,\n 'yelp': 809,\n 'erwähnen': 810,\n 'rechtfertigen': 811,\n 'samstag': 812,\n 'traditionell': 813,\n 'außergewöhnlich': 814,\n 'schließen': 815,\n 'flair': 816,\n 'issen': 817,\n 'wunsch': 818,\n 'gegess': 819,\n 'deutschland': 820,\n 'begrüßung': 821,\n 'zurück': 822,\n 'deswegen': 823,\n 'ouzo': 824,\n 'langweilig': 825,\n 'bereich': 826,\n 'meckern': 827,\n 'lässen': 828,\n 'offensichtlich': 829,\n 'handeln': 830,\n 'gastraum': 831,\n 'fettig': 832,\n 'äußerst': 833,\n 'anfang': 834,\n 'hoffen': 835,\n 'spontan': 836,\n 'knoblauch': 837,\n 'hähnchen': 838,\n 'rindfleisch': 839,\n 'üppig': 840,\n 'currywurst': 841,\n 'moderat': 842,\n 'enttäuschend': 843,\n 'na': 844,\n 'hierher': 845,\n 'besitzer': 846,\n 'passieren': 847,\n 'salz': 848,\n 'bedienunge': 849,\n 'schawarma': 850,\n 'lauwarm': 851,\n 'deftig': 852,\n 'nämlich': 853,\n 'meistens': 854,\n 'keiner': 855,\n 'abendessen': 856,\n 'lässt': 857,\n 'sowas': 858,\n 'mindestens': 859,\n 'genauso': 860,\n 'empfangen': 861,\n 'dadurch': 862,\n 'vorab': 863,\n 'kombination': 864,\n 'bemühen': 865,\n 'viele': 866,\n 'unterschiedlich': 867,\n 'darüber': 868,\n 'the': 869,\n 'thailändisch': 870,\n 'ausgesprochen': 871,\n 'beitrag': 872,\n 'versprechen': 873,\n 'sauberkeit': 874,\n 'verlassen': 875,\n 'ihm': 876,\n 'schick': 877,\n 'entweder': 878,\n 'hungrig': 879,\n 'foto': 880,\n 'gesamt': 881,\n 'vorstellen': 882,\n 'and': 883,\n 'to': 884,\n 'willkommen': 885,\n 'nah': 886,\n 'umgebung': 887,\n 'bequem': 888,\n 'häufig': 889,\n 'geschmackvoll': 890,\n 'prima': 891,\n 'fett': 892,\n 'herrlich': 893,\n 'englisch': 894,\n 'vergeben': 895,\n 'woanders': 896,\n 'ei': 897,\n 'suche': 898,\n 'cocktail': 899,\n 'inzwischen': 900,\n 'bratkartoffeln': 901,\n 'freitag': 902,\n 'schwierig': 903,\n 'reichhaltig': 904,\n 'ausgezeichnet': 905,\n 'standard': 906,\n 'produkt': 907,\n 'cocktails': 908,\n 'beschreiben': 909,\n 'charmant': 910,\n 'gastronomie': 911,\n 'interieur': 912,\n 'mexikanisch': 913,\n 'zusammenstellen': 914,\n 'pane': 915,\n 'kritik': 916,\n 'eingang': 917,\n 'spanisch': 918,\n 'draussen': 919,\n 'mitbringen': 920,\n 'außer': 921,\n 'detail': 922,\n 'vermutlich': 923,\n 'empfang': 924,\n 'witzig': 925,\n 'mischung': 926,\n 'nennen': 927,\n 'brötchen': 928,\n 'boden': 929,\n 'kreuzberg': 930,\n 'jederzeit': 931,\n 'zunächst': 932,\n 'betreiber': 933,\n 'möglichkeit': 934,\n 'ach': 935,\n 'n': 936,\n 'winter': 937,\n 'zentral': 938,\n 'wahr': 939,\n 'wechselnd': 940,\n 'unschlagbar': 941,\n 'überall': 942,\n 'optisch': 943,\n 'alleine': 944,\n 'hell': 945,\n 'verzichten': 946,\n 'bestelln': 947,\n 'solide': 948,\n 'vorzüglich': 949,\n 'all': 950,\n 'aufdringlich': 951,\n 'klassiker': 952,\n 'fan': 953,\n 'beispiel': 954,\n 'verweilen': 955,\n 'abschluss': 956,\n 'erfüllen': 957,\n 'gelten': 958,\n 'schlimm': 959,\n 'bitten': 960,\n 'chicken': 961,\n 'kleinigkeit': 962,\n 'manko': 963,\n 'schluss': 964,\n 'monat': 965,\n 'gewürz': 966,\n 'rundum': 967,\n 'hören': 968,\n 'mehrmals': 969,\n 'stil': 970,\n 'beef': 971,\n 'cafe': 972,\n 'speziell': 973,\n 'ändern': 974,\n 'öffnen': 975,\n 'fenster': 976,\n 'abwechslungsreich': 977,\n 'chili': 978,\n 'trinkgeld': 979,\n 'roh': 980,\n 'gebacken': 981,\n 'dame': 982,\n 'bibimbap': 983,\n 'ding': 984,\n 'gross': 985,\n 'familiär': 986,\n 'flink': 987,\n 'zufällig': 988,\n 'weinauswahl': 989,\n 'spinat': 990,\n 'orientalisch': 991,\n 'lieblos': 992,\n 'würzig': 993,\n 'hab': 994,\n 'soßen': 995,\n 'einladend': 996,\n 'filet': 997,\n 'kiez': 998,\n 'gespräch': 999,\n 'wünsche': 1000,\n ...}"
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "\n",
    "comments_array = asarray(yelp['Lemmatized_Comment'])\n",
    "vocab_size = 25000\n",
    "tokenizer=Tokenizer(num_words=vocab_size)\n",
    "#get index per word\n",
    "tokenizer.fit_on_texts(comments_array)\n",
    "tokenizer.word_index"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6, 8, 23, 311, 7, 35, 21, 15267, 1438, 3, 40, 35, 8, 13, 916, 102, 8, 6, 9, 429, 3, 9, 10, 2422], [1, 2825, 2, 4, 245, 198, 4338, 35, 5, 472, 1295, 9, 2, 182, 10, 173, 2719, 17, 162, 945, 3, 762, 350, 14, 70, 4339, 1, 43, 2, 871, 47, 1420, 3, 145, 173, 15268, 1, 19, 39, 94, 126, 11, 1602, 55, 3, 27, 76, 9, 12, 1, 4338, 3597, 962, 3, 512, 8, 64, 11, 13, 76, 1, 37, 2, 289, 3, 20, 66, 215, 10, 7, 212, 15, 2, 36, 42, 580, 373, 52, 79, 11, 201, 453, 3793, 18, 15, 24, 64, 156, 10, 67, 1007, 22, 134, 68, 687, 21, 3423, 18, 1, 42, 10575, 218, 81, 4338, 85, 219, 13, 37, 256, 390, 206, 14, 348, 21, 1, 763, 3, 54, 43, 2, 28, 11, 13, 1083], [15269, 5562, 8, 15, 23, 224, 10576, 15270, 2826, 3, 2825, 18, 7, 6206, 15271, 31, 34, 3, 8370, 67, 30, 1, 301, 30, 6, 550, 39, 1439, 9, 5563, 17, 6, 2, 40, 305, 71, 10577, 2197, 15272, 3, 34, 8370, 14, 75, 546, 1019, 3424, 2, 1, 379, 4340, 8, 105, 67, 15273, 17, 2, 7, 1629], [19, 2, 4663, 149, 186, 6, 10, 398, 8, 229, 2, 33, 662, 5, 2825, 11, 825, 418, 6, 730, 5, 35, 39, 470, 9, 764, 110, 6, 739, 3, 1296, 15274, 1, 125, 2, 10, 101, 1, 269, 21, 894, 61, 95, 5, 66, 215, 10, 58, 2423, 6, 96, 4, 614, 10578, 136, 30, 250, 3, 387, 4, 10579, 14, 261, 5, 1, 304, 85, 197, 39, 9, 48, 255, 214, 22, 68, 22, 3242, 3, 7085, 1, 4341, 120, 222, 77, 5, 33, 138, 7086, 136, 2, 90, 382, 1, 564, 3598, 30, 303, 7, 136, 1054, 8, 75, 13, 76, 1, 10579, 568, 55, 479, 1474, 1654, 1498, 3, 3083, 8371, 21, 7087, 794, 5564, 1983, 143, 1154, 124, 15275, 452, 14, 4, 10580, 8372, 504, 6, 135, 220, 109, 41, 273, 75, 13, 1184, 5, 66, 4, 20, 15276, 5565, 85, 57, 12, 20, 35, 712, 5, 7088, 763, 3794, 558], [2, 21, 203, 80, 3, 18, 10, 316, 551, 88, 551, 19, 808, 100, 15, 2, 7, 41, 3, 8, 64, 61, 452, 421, 165, 170, 34, 6, 30, 652, 2, 12, 101, 21, 33, 337, 39, 9, 78, 58, 1044, 3, 27, 2, 12, 1, 517, 1, 16, 547, 89, 96, 3, 34, 4053, 531]]\n"
     ]
    }
   ],
   "source": [
    "def int_encode_comments(comment_list, tokenizer):\n",
    "    return tokenizer.texts_to_sequences(comment_list)\n",
    "\n",
    "embedded_comments = int_encode_comments(comments_array, tokenizer)\n",
    "print(embedded_comments[:5])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### LSTM Model Preparation\n",
    "\n",
    "1) Define padding size"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "779\n"
     ]
    }
   ],
   "source": [
    "def get_max_token_length_per_cmt(Comments_arr: list[str])-> int:\n",
    "    return max(list(map(lambda x: len(x.split()),Comments_arr)))\n",
    "padding_size = get_max_token_length_per_cmt(comments_array)\n",
    "print(str(padding_size))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "2) Pad embedded comments"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [],
   "source": [
    "padded_cmts = pad_sequences(embedded_comments, maxlen=padding_size)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "3. One-Hot-Encoding of Rating\n",
    "Q: https://www.atmosera.com/blog/multiclass-classification-with-neural-networks/"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       5\n",
      "1       4\n",
      "2       5\n",
      "3       2\n",
      "4       5\n",
      "       ..\n",
      "9701    3\n",
      "9702    3\n",
      "9703    5\n",
      "9704    5\n",
      "9705    5\n",
      "Name: Rating, Length: 9706, dtype: int64\n",
      "[[0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 1.]\n",
      " ...\n",
      " [0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# need to pre-encode labels (1-5) to (0-4) because to_categorical assumes 0 as lowest label value\n",
    "# otherwise we would get 6 classes in the one-hot encoded arrays\n",
    "\n",
    "yelp['Rating_Encoded'] = LabelEncoder().fit_transform(yelp['Rating'])\n",
    "print(yelp.Rating)\n",
    "print(to_categorical(yelp.Rating))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Train-Dev-Test Split"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [],
   "source": [
    "seed=101010\n",
    "y=yelp[\"Rating_Encoded\"]\n",
    "\n",
    "X_train_dev, X_test, y_train_dev, y_test = train_test_split(padded_cmts, y, test_size = 0.1, random_state=seed)\n",
    "X_train, X_dev, y_train, y_dev = train_test_split(X_train_dev, y_train_dev, test_size = 0.1, random_state=seed)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Define LSTM Model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_12\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_12 (Embedding)    (None, 779, 128)          3200000   \n",
      "                                                                 \n",
      " lstm_12 (LSTM)              (None, 128)               131584    \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 5)                 645       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,332,229\n",
      "Trainable params: 3,332,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras import optimizers\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=vocab_size,  output_dim=128, input_length=padding_size))\n",
    "model.add(LSTM(units=128, activation='tanh'))\n",
    "#model.add(Flatten())\n",
    "model.add(Dense(5, activation='sigmoid'))\n",
    "opt = optimizers.RMSprop(learning_rate=1e-06)\n",
    "model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Train LSTM Model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "246/246 [==============================] - 223s 897ms/step - loss: 1.6092 - accuracy: 0.2152 - val_loss: 1.6080 - val_accuracy: 0.2700\n",
      "Epoch 2/2\n",
      "246/246 [==============================] - 206s 839ms/step - loss: 1.6073 - accuracy: 0.2746 - val_loss: 1.6059 - val_accuracy: 0.3135\n"
     ]
    }
   ],
   "source": [
    "hist = model.fit(X_train,\n",
    "                 to_categorical(y_train),\n",
    "                 #batch_size=128,\n",
    "                 epochs=2,\n",
    "                 validation_data=(X_dev,to_categorical(y_dev)))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31/31 [==============================] - 8s 232ms/step\n",
      "[4 3 3 2 4 2 2 4 3 3 3 3 3 2 3 3 4 4 2 4 3 3 4 2 2 3 3 4 4 4 3 4 3 4 4 4 4\n",
      " 4 0 1 3 2 4 2 4 2 1 1 3 3 3 4 4 4 3 1 3 4 4 1 2 4 4 2 4 4 4 2 4 1 4 2 4 2\n",
      " 4 3 4 4 4 3 4 4 4 4 2 2 3 2 4 2 3 4 2 4 3 4 4 0 3 2 4 4 4 2 4 2 4 4 2 4 4\n",
      " 3 1 4 1 4 1 3 1 4 4 3 1 4 3 3 4 4 4 0 2 2 3 4 4 3 2 4 2 3 4 3 3 4 4 4 4 4\n",
      " 4 4 4 3 4 4 3 4 4 4 4 4 4 2 3 1 3 4 1 3 3 4 2 3 0 1 2 3 4 2 4 2 3 4 3 4 4\n",
      " 3 4 3 2 4 4 2 3 4 3 2 3 3 3 4 2 4 3 3 2 4 4 4 4 4 4 4 3 4 3 3 4 4 4 3 3 4\n",
      " 3 2 3 2 3 1 4 4 4 3 4 4 3 3 2 3 4 4 4 4 4 4 4 2 0 3 4 4 4 1 2 3 4 3 4 3 4\n",
      " 2 2 1 1 3 3 3 4 3 3 4 2 4 4 2 4 4 3 2 4 2 1 2 4 3 2 3 4 3 4 2 4 4 4 3 3 2\n",
      " 3 4 1 3 3 2 1 0 4 4 3 4 3 4 3 4 4 3 3 4 2 4 4 2 4 3 3 2 4 4 4 3 4 3 2 4 4\n",
      " 4 3 4 3 4 3 3 4 4 4 4 4 3 4 2 4 4 3 2 2 3 4 4 3 4 3 2 4 3 3 2 4 4 3 4 4 3\n",
      " 4 4 4 3 4 4 4 3 3 3 2 2 1 4 3 4 3 2 4 3 3 2 3 4 3 2 3 4 4 1 3 4 4 1 4 4 4\n",
      " 3 4 2 4 0 4 4 1 4 3 4 2 4 0 2 2 2 0 2 3 4 2 2 3 3 2 3 4 2 3 4 4 2 4 2 4 4\n",
      " 4 4 4 2 3 2 4 3 4 4 4 4 1 4 3 2 3 4 4 3 2 3 4 0 4 4 3 4 3 4 4 4 3 4 4 2 3\n",
      " 3 4 4 4 1 3 4 3 4 2 4 3 2 1 4 3 3 4 3 2 4 3 0 3 3 3 4 3 0 4 3 4 4 3 4 2 4\n",
      " 4 3 0 4 3 4 2 4 2 3 3 4 4 3 4 2 2 2 2 3 4 4 3 2 3 3 3 2 3 2 4 4 2 4 4 4 4\n",
      " 4 4 4 4 2 4 4 3 0 4 2 1 4 3 2 3 4 4 3 2 3 2 4 2 3 0 0 4 4 4 4 3 2 3 4 4 4\n",
      " 4 4 3 3 3 2 4 0 4 4 2 2 4 2 4 4 3 4 4 3 2 3 2 3 2 2 3 4 4 4 3 4 3 3 4 1 3\n",
      " 4 2 4 2 2 3 4 0 3 4 4 2 2 4 4 4 2 4 0 4 3 3 3 3 4 3 3 2 3 1 4 2 4 3 3 3 3\n",
      " 3 4 2 3 2 3 4 0 3 3 4 4 3 2 2 1 4 0 4 3 4 3 1 1 3 4 4 3 2 3 2 0 3 3 4 1 3\n",
      " 2 2 4 3 3 2 3 1 3 3 4 3 4 4 4 4 4 3 2 3 4 4 3 4 4 4 3 0 4 2 3 4 4 2 2 1 4\n",
      " 3 4 1 3 2 4 3 3 4 1 2 2 3 3 4 3 4 2 4 4 4 3 3 4 3 2 2 2 1 2 2 3 3 0 4 4 0\n",
      " 4 3 3 3 3 4 3 4 4 4 1 4 4 4 3 1 2 3 4 0 4 4 3 3 3 4 1 4 4 2 2 4 2 4 4 2 2\n",
      " 4 4 0 3 4 2 1 4 2 1 2 3 4 4 4 3 2 4 4 3 2 3 2 1 3 4 4 3 4 4 2 4 4 4 3 4 4\n",
      " 1 4 4 4 3 3 2 3 2 4 4 4 4 3 2 2 1 2 3 1 3 3 3 2 3 3 4 2 1 4 4 3 1 4 3 3 4\n",
      " 3 2 2 4 4 3 4 3 2 4 3 3 4 4 4 0 4 4 4 4 4 4 1 3 4 3 4 4 4 2 2 2 4 2 3 3 3\n",
      " 3 2 4 3 4 4 3 4 1 0 4 3 3 4 3 2 4 3 3 3 4 4 3 2 4 2 2 4 3 2 4 4 3 1 4 4 4\n",
      " 1 2 4 3 3 4 3 4 3]\n",
      "0.32440782698249226\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score,precision_score,recall_score,accuracy_score\n",
    "import numpy as np\n",
    "pred_test= np.argmax(model.predict(X_test), axis=1)\n",
    "print(pred_test)\n",
    "print(accuracy_score(pred_test,y_test))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
