{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Modelling with TF-IDF Vectorization\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "                                             Comment  Rating  \\\n0  ich habe mir  bewertungen zu  restaurants auf ...       5   \n1  das  joseph ist ein ziemlich neues israelische...       4   \n2  schalömchen scheiße haben wir uns heute kosche...       5   \n3  essen war allenfalls ok muss ich nicht nochmal...       2   \n4  waren auf  empfehlung dort und wurden nicht en...       5   \n\n                                       Clean_Comment  \\\n0  ich habe mir  bewertungen zu  restaurants auf ...   \n1  das  joseph ist ein ziemlich neues israelische...   \n2  schalömchen scheiße haben wir uns heute kosche...   \n3  essen war allenfalls ok muss ich nicht nochmal...   \n4  waren auf  empfehlung dort und wurden nicht en...   \n\n                                   Tokenized_Comment  \\\n0  bewertungen restaurants menulist angesehen res...   \n1  joseph ziemlich neues israelisches restaurant ...   \n2  schalömchen scheiße heute koscher weggeknallt ...   \n3  essen allenfalls ok nochmal insgesamt erlebnis...   \n4  empfehlung wurden enttäuscht hammer ambiente h...   \n\n                                  Lemmatized_Comment  Senti_Blob  Senti_norm  \n0  ich haben sich   bewertung zu   restaurant auf...    1.000000    5.000000  \n1  der   joseph sein ein ziemlich neu israelisch ...    0.846429    4.692857  \n2  schalömch scheiße haben wir sich heute kosch w...    0.283333    3.566667  \n3  essen sein allenfalls ok mussen ich nicht noch...    0.133333    3.266667  \n4  sein auf   empfehlung dort und werden nicht en...    0.750000    4.500000  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Comment</th>\n      <th>Rating</th>\n      <th>Clean_Comment</th>\n      <th>Tokenized_Comment</th>\n      <th>Lemmatized_Comment</th>\n      <th>Senti_Blob</th>\n      <th>Senti_norm</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>ich habe mir  bewertungen zu  restaurants auf ...</td>\n      <td>5</td>\n      <td>ich habe mir  bewertungen zu  restaurants auf ...</td>\n      <td>bewertungen restaurants menulist angesehen res...</td>\n      <td>ich haben sich   bewertung zu   restaurant auf...</td>\n      <td>1.000000</td>\n      <td>5.000000</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>das  joseph ist ein ziemlich neues israelische...</td>\n      <td>4</td>\n      <td>das  joseph ist ein ziemlich neues israelische...</td>\n      <td>joseph ziemlich neues israelisches restaurant ...</td>\n      <td>der   joseph sein ein ziemlich neu israelisch ...</td>\n      <td>0.846429</td>\n      <td>4.692857</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>schalömchen scheiße haben wir uns heute kosche...</td>\n      <td>5</td>\n      <td>schalömchen scheiße haben wir uns heute kosche...</td>\n      <td>schalömchen scheiße heute koscher weggeknallt ...</td>\n      <td>schalömch scheiße haben wir sich heute kosch w...</td>\n      <td>0.283333</td>\n      <td>3.566667</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>essen war allenfalls ok muss ich nicht nochmal...</td>\n      <td>2</td>\n      <td>essen war allenfalls ok muss ich nicht nochmal...</td>\n      <td>essen allenfalls ok nochmal insgesamt erlebnis...</td>\n      <td>essen sein allenfalls ok mussen ich nicht noch...</td>\n      <td>0.133333</td>\n      <td>3.266667</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>waren auf  empfehlung dort und wurden nicht en...</td>\n      <td>5</td>\n      <td>waren auf  empfehlung dort und wurden nicht en...</td>\n      <td>empfehlung wurden enttäuscht hammer ambiente h...</td>\n      <td>sein auf   empfehlung dort und werden nicht en...</td>\n      <td>0.750000</td>\n      <td>4.500000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yelp = pd.read_csv('yelp_cleaned_sentiscored.csv')\n",
    "yelp.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 754)\t0.4241610243114664\n",
      "  (0, 4085)\t0.10419735162670914\n",
      "  (0, 485)\t0.2912112864011511\n",
      "  (0, 1800)\t0.2063167666104816\n",
      "  (0, 141)\t0.20211466669651104\n",
      "  (0, 3299)\t0.347675355822079\n",
      "  (0, 2573)\t0.09819467679215284\n",
      "  (0, 1343)\t0.15684547169528526\n",
      "  (0, 270)\t0.38269074774378\n",
      "  (0, 369)\t0.12108218348116806\n",
      "  (0, 4656)\t0.2958710931984148\n",
      "  (0, 6658)\t0.09494880442320777\n",
      "  (0, 855)\t0.2724001551484482\n",
      "  (0, 5119)\t0.12829439166012327\n",
      "  (0, 2595)\t0.3070877667009214\n",
      "  (0, 2896)\t0.20798137667768696\n",
      "  (1, 393)\t0.12473831855268705\n",
      "  (1, 2744)\t0.047904446879624085\n",
      "  (1, 4065)\t0.05442354355065734\n",
      "  (1, 2079)\t0.11685699977158848\n",
      "  (1, 936)\t0.09692882882756876\n",
      "  (1, 3957)\t0.08633665216168444\n",
      "  (1, 6052)\t0.09849370149051788\n",
      "  (1, 3488)\t0.08856394946896615\n",
      "  (1, 3958)\t0.08747350446354939\n",
      "  :\t:\n",
      "  (9704, 5049)\t0.2736736445068207\n",
      "  (9704, 4940)\t0.2743118212468185\n",
      "  (9704, 1805)\t0.14725312067770818\n",
      "  (9704, 1514)\t0.23699397269705308\n",
      "  (9704, 4085)\t0.14681444203402041\n",
      "  (9704, 6658)\t0.1337832058642971\n",
      "  (9705, 3791)\t0.44076310256941387\n",
      "  (9705, 4930)\t0.4512307007158668\n",
      "  (9705, 755)\t0.34468491204246854\n",
      "  (9705, 6204)\t0.1916395759504304\n",
      "  (9705, 685)\t0.14963422256953632\n",
      "  (9705, 3483)\t0.17838128650400184\n",
      "  (9705, 2083)\t0.18595621348926464\n",
      "  (9705, 3185)\t0.16607192563107384\n",
      "  (9705, 5486)\t0.17125977012819651\n",
      "  (9705, 3641)\t0.184842101607912\n",
      "  (9705, 120)\t0.15199520292991064\n",
      "  (9705, 6052)\t0.28887258252892484\n",
      "  (9705, 3375)\t0.19031248297797487\n",
      "  (9705, 1823)\t0.1569500600246755\n",
      "  (9705, 4141)\t0.14856651498658124\n",
      "  (9705, 2923)\t0.1855295408680913\n",
      "  (9705, 1514)\t0.0856210584561288\n",
      "  (9705, 2573)\t0.09997083744886992\n",
      "  (9705, 1343)\t0.15968251709438638\n"
     ]
    }
   ],
   "source": [
    "# Q: https://melaniewalsh.github.io/Intro-Cultural-Analytics/05-Text-Analysis/03-TF-IDF-Scikit-Learn.html\n",
    "\n",
    "#help(TfidfVectorizer)\n",
    "# max_features: int, default=None --> If not None, build a vocabulary that only considers the top\n",
    "# max_features ordered by term frequency across the corpus\n",
    "# max/min_df: ignore terms that have a document frequency strictly higher/lower than given threshold\n",
    "# setting lower and upper frequency thresholds as done in reference paper Luo, Xu\n",
    "doc_frequency=0.8\n",
    "min_absolute_frequency=5\n",
    "\n",
    "tfidf = TfidfVectorizer(min_df=min_absolute_frequency, max_df=doc_frequency)\n",
    "#tfidf = TfidfVectorizer()\n",
    "X_tfidf = tfidf.fit_transform(yelp['Lemmatized_Comment'])\n",
    "print(X_tfidf)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Split dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Model selection"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
