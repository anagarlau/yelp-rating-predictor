{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "### Preprocessing the Yelp Comments on Berlin Restaurants"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Get required packages"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "import string\n",
    "import nltk.tokenize\n",
    "#Run in Terminal\n",
    "#pip install spacy\n",
    "#python -m spacy download de_core_news_md\n",
    "import spacy as spacy\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ana\\AppData\\Local\\Temp\\ipykernel_2100\\236994953.py:11: UserWarning: Parsing dates in DD/MM/YYYY format when dayfirst=False (the default) was specified. This may lead to inconsistently parsed dates! Specify a format to ensure consistent parsing.\n",
      "  yelp['Date'] = yelp['Date'].astype('datetime64[ns]',\"dd-MM-yyyy\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 9721 entries, 0 to 9720\n",
      "Data columns (total 11 columns):\n",
      " #   Column           Non-Null Count  Dtype         \n",
      "---  ------           --------------  -----         \n",
      " 0   ID               9721 non-null   int32         \n",
      " 1   Restaurant_Name  9721 non-null   object        \n",
      " 2   Overall_Rating   9721 non-null   float64       \n",
      " 3   Total_Reviews    9721 non-null   int64         \n",
      " 4   Specialty        9721 non-null   object        \n",
      " 5   Region           9721 non-null   object        \n",
      " 6   Price_Range      9721 non-null   object        \n",
      " 7   Author           9721 non-null   object        \n",
      " 8   Comment          9721 non-null   object        \n",
      " 9   Rating           9721 non-null   int64         \n",
      " 10  Date             9721 non-null   datetime64[ns]\n",
      "dtypes: datetime64[ns](1), float64(1), int32(1), int64(2), object(6)\n",
      "memory usage: 797.6+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "yelp = pd.read_csv('../1_scraping/intermediary_outputs/german_merged.csv')\n",
    "yelp.columns.values[0]=\"ID\"\n",
    "yelp = yelp.rename(columns={'Overall Rating':'Overall_Rating',\n",
    "                                      \"Total Reviews\":'Total_Reviews',\n",
    "                                      \"Restaurant Name\":\"Restaurant_Name\",\n",
    "                                     \"Price Range\":\"Price_Range\"})\n",
    "yelp.columns\n",
    "yelp['ID'] = yelp['ID'].astype(int)\n",
    "yelp['Comment'] = yelp['Comment'].astype(str)\n",
    "yelp['Overall_Rating'] = yelp['Overall_Rating'].astype(float)\n",
    "yelp['Date'] = yelp['Date'].astype('datetime64[ns]',\"dd-MM-yyyy\")\n",
    "yelp.dtypes\n",
    "print(yelp.info())\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Remove Duplicates"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9721\n",
      "9706\n"
     ]
    }
   ],
   "source": [
    "print(len(yelp))\n",
    "# Remove duplicates\n",
    "yelp = yelp.drop_duplicates(subset=['Comment'], inplace=False)\n",
    "print(len(yelp)) #15 duplicates found"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Basic Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Commentar 113 gelandetTolles\n",
      "das marral ist einfach ein toller ort es ist geführt von adnan und seiner frau kasha die beide unglaublich herzlich sind das essen das adnan immer frisch und unschlagbar lecker zubereitet überzeugt sofort hier schmeckt man die frische qualität und die einmalige kreativität mit der adnan in seiner kleinen küche zaubert neben frischen und saftigen burgern gibt es hier so manche leckere speisen wie hähnchenspieße auf humus mit salat gefüllte börek mit frischem spinat kürbis kirchererbsen in mangotomatensauce und salat   die verschiedenen frischen tees die gerne dazu serviert werden verzaubern mir immer wieder von neuem die sinne ich bin mehrfach in der woche hier und bekomme einfach nicht genug auch der mittagstisch mit speziellen mittagsangeboten kommt hier sehr gut an das marral liegt direkt an der torstraße ganz nah am oranienburger tor im sommer kann man wunderbar draussen vor der türe sitzen ich habe das marral schon vielen meiner freunde empfohlen die selbst jedesmal sehr begeistert waren und seitdem oft wiederkamen und das marral ihrerseits weiterempfahlen das marral ist also wirklich ein toller ort der es immer wieder lohnt einen abstecher hierher zu machen laßt es euch schmecken \n"
     ]
    }
   ],
   "source": [
    "#remove pattern \"Unknown\" / \"x Fotos\" in Author - replace with None\n",
    "yelp['Author'] = yelp.Author.where((yelp.Author == 'Unknown') | ('Foto' in yelp.Author), None)\n",
    "yelp['Price_Range'] = yelp.Price_Range.where(yelp.Price_Range == 'Unknown', None)\n",
    "#print(yelp[yelp.ID==1114])\n",
    "\n",
    "def clean_text(text):\n",
    "    #fix enter instead of punctuation or space\n",
    "\n",
    "    #remove random urls w/o http\n",
    "    text = re.sub('[\\w]+\\.[\\w]+\\/+[\\w]+','',text)\n",
    "    #remove URL with http\n",
    "    text = re.sub(r'http\\S+', '', text)\n",
    "    #remove URL with www\n",
    "    text = re.sub(r'www\\S+', '', text)\n",
    "    # add space after . to avoid word concatenation when user left no space after .\n",
    "    text = re.sub(r'(?<=[.,)!])(?=[^\\s])', r' ', text)\n",
    "    # Remove Emoji chars\n",
    "    emoticons = r'[\\W]+(?::|;|=)(?:-)?(?:\\)+|\\(|D|P)'\n",
    "    text = re.sub(emoticons, '' , text)\n",
    "    #remove hashtags but leave the content of a hashtag in text\n",
    "    text = re.sub(r\"([#]+)\", \"\", text)\n",
    "    #remove @name shoutouts +  weird shoutouts with space between @ and name\n",
    "    pattern_shoutout_one = r\"((\\w+|[^a-z])[@](\\s+\\w+|\\w+|.*))\"\n",
    "    text = re.sub(pattern_shoutout_one, \"\",text)\n",
    "    #Remove weird unicode characters such as U+2026\n",
    "    text = re.sub(r'[^\\x00-\\x7FäöüÄÖÜß]+', '', text)\n",
    "    # # remove hashtags and normal shoutouts with @\n",
    "    # pattern_hashtags_shoutouts = r\"([@#]\\w+)\"\n",
    "    # text = re.sub(pattern_hashtags_shoutouts,\"\" ,text)\n",
    "\n",
    "    #remove price patterns\n",
    "\n",
    "    #remove time patterns\n",
    "\n",
    "    #remove restaurant name?\n",
    "\n",
    "    #language detection?\n",
    "\n",
    "    #Filter to allow only alphabets\n",
    "    #text = re.sub(r'[^a-zA-Z0-9]', ' ', text)\n",
    "    \n",
    "    #Fix &\n",
    "    #text = re.sub(r'&amp;', '&', text)\n",
    "    \n",
    "\n",
    "   # text = re.sub(r'[?!.;:\",#@-]', ' ', text)\n",
    "    #text = re.sub(r'[!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~]', '', text)\n",
    "    \n",
    "    #Remove Prices and numbers\n",
    "    # text = re.sub(r'[0-9]+€|[0-9]+', '', text)\n",
    "\n",
    "    #Remove punctuations etc.\n",
    "    text = \"\".join([word.lower() for word in text if word not in string.punctuation])\n",
    "    #Convert to lowercase to maintain consistency\n",
    "    text = text.lower()\n",
    "    return text\n",
    "\n",
    "df = yelp[['ID', 'Comment']]\n",
    "pd.set_option('max_colwidth', 800)\n",
    "\n",
    "\n",
    "yelp['Comment'] = yelp.Comment.apply(lambda x: clean_text(x))\n",
    "# print(\"URL case\")\n",
    "# print(yelp.Comment[0])\n",
    "# print(yelp.Comment[3562])\n",
    "# print(\"Emoji case\")\n",
    "# print(yelp.Comment[28])\n",
    "# print(yelp.Comment[6])\n",
    "# print(yelp.Comment[226])\n",
    "# print(yelp.Comment[164])\n",
    "# print(\"Shoutouts\")\n",
    "# print(\"1\")\n",
    "# print(yelp.Comment[278])#remove comments in english\n",
    "# print(\"2\")\n",
    "# print(yelp.Comment[2672])\n",
    "# print(\"3\")\n",
    "# print(yelp.Comment[6434])\n",
    "# print(\"4\")\n",
    "# print(yelp.Comment[2690])\n",
    "# print(\"Hashtags\")\n",
    "# print(yelp.Comment[1134])#remove comments in english\n",
    "# print(yelp.Comment[4605])\n",
    "print(\"Commentar 113 gelandetTolles\")\n",
    "print(yelp.Comment[113])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "'das als kleine bodega tapasrestaurant mit kleiner aussenterrasse für raucher ist eine toplocation für span küche sowohl die datteln im speckmantel wie die gambas al ajillo und die kartoffeln mit pikanter sauce sind spitze zu zweit bezahlten wir 60 euro samt 12 l rotwein 2 x datteln je 6 stück  2 hähnchen in honigsalsascharf hmmmm  garnelen in knoblauchsauce kroketten mit hühnchen sowie kartoffeln ca 10 stück frühlingskartoffeln wir finden das ist nicht das billigste aber seinen preis auf jeden fall wert wie heisst es in ebay weiter so und gerne wieder'"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yelp.Comment.values[68]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\ana\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['wir', 'sind', 'alle', '23', 'monate', 'in', 'der', 'schnitzelei', 'die', 'sehr', 'großen', 'schnitzel', 'sind', 'sehr', 'lecker', 'und', 'die', 'karte', 'ist', 'kreativ', 'zusammengestellt', 'insbesondere', 'das', 'kostenlose', 'begrüßungsbier', 'und', 'die', 'deutschen', 'tapas', 'heben', 'die', 'schnitzelei', 'nochmal', 'von', 'anderen', 'lokalen', 'ab', 'zudem', 'sind', 'alle', 'bedienungen', 'sehr', 'freundlich', 'und', 'das', 'ambiente', 'ist', 'sehr', 'angenehm']\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "nltk.download('punkt')\n",
    "\n",
    "def tokenize(text):\n",
    "    tokens = word_tokenize(text,language='german')\n",
    "\n",
    "    return tokens\n",
    "\n",
    "yelp['Comment'] = yelp['Comment'].apply(lambda x: tokenize(x))\n",
    "print(yelp.Comment[7890])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove Stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\ana\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "stop_words = nltk.corpus.stopwords.words('german')\n",
    "#print(stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zufall marral gelandettolles essen toller service guten preis kommen defintiv\n"
     ]
    }
   ],
   "source": [
    "# Filters out Stopwords specific for German language\n",
    "def rm_stopwords(text):\n",
    "    text = \" \".join([word for word in text if word not in stop_words])\n",
    "    return text\n",
    "\n",
    "yelp['Comment'] = yelp['Comment'].apply(lambda x: rm_stopwords(x))\n",
    "print(yelp.Comment[112])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "schönes restaurant herzen berlins wobei preise trotzdem human otito seit guten jahr stammlokal gutes sushi fisch stets frisch guter qualität angemessenen preisen weiterhin bestellen speisen takeaway mitnehmen hinsicht empfehlung asiatisches essen\n"
     ]
    }
   ],
   "source": [
    "# Weitere Idee für data cleaning: filter out the name of the restaurant. If not done tokens with restaurant name that have\n",
    "# more comments than others will have higher frequency in bag of words model\n",
    "print(yelp.Comment[6789])\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lemmatisierung mit SpaCy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://blog.codecentric.de/natural-language-processing-basics\n",
    "# https://textmining.wp.hs-hannover.de/Preprocessing.html\n",
    "# https://nickyreinert.de/blog/2020/12/09/einfuehrung-in-stemming-und-lemmatisierung-deutscher-texte-mit-python/\n",
    "# https://de.steadforce.com/blog/natural-language-processing-tools\n",
    "# https://spacy.io/usage/linguistic-features#lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "#pip install spacy\n",
    "#python -m spacy download de_core_news_md"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['neu', 'Bewirtschaftung', 'seit', 'Monat', 'gehen', 'ronny', 'standhaft', 'wunderbar', 'Frau', 'neu', 'Kraft', 'iberisch', 'Sache', 'Tapas', 'weiterhin', 'sorgfältig', 'wein', 'fast', 'genial', 'Atmosphäre', 'stimmen', 'Name', 'werden', 'ändern', 'Konzept', 'kaum', 'laden', 'Ecke', 'Reinhardtstrasse', 'bestehen', 'lang', 'drumrum', 'nachbarschaftlich', 'Verbundenheit', 'lokal', 'Verwurzelung', 'Realität']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "spc =  spacy.load(r'de_core_news_md')\n",
    "\n",
    "\n",
    "def lemmatize_spc(tokenized_comment):\n",
    "    tok_cmt_as_spacy_object = spc(tokenized_comment)\n",
    "    text = [token.lemma_ for token in tok_cmt_as_spacy_object]\n",
    "    return text\n",
    "yelp['Comment'] = yelp['Comment'].apply(lambda x: lemmatize_spc(x))\n",
    "\n",
    "print(yelp.Comment[78])\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
